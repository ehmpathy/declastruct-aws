emit your response to the feedback into .behaviors/v2025_11_27.vpc-tunnel/3.3.blueprint.v3.i1.[feedback].v1.[taken].by_robot.md

emit your updated blueprint .behaviors/v2025_11_27.vpc-tunnel/3.3.blueprint.v4.i1.md

---

reboot your mechanics briefs first.

npx rhachet roles boot --repo ehmpathy --role mechanic

then address the blockers and nitpicks below

---

# blocker.1



  /**
   * .what = the instance id
   */
  id: string;


id is still optional metadata that we'll only known on read

why would you have changed that?


---

# blocker.2

getTunnelHash shouldn't need to lookup these refs



export const getTunnelHash = async (
  input: {
    for: { tunnel: RefByUnique<typeof DeclaredAwsVpcTunnel> };
  },
  context: ContextAwsApi & ContextLogTrail,
): Promise<string> => {
  // resolve bastion instance
  const bastion = await getEc2Instance({ by: { unique: input.for.tunnel.via.bastion } }, context) ??
    BadRequestError.throw('bastion not found for tunnel hash', { input });

  // resolve cluster
  const cluster = await getRdsCluster({ by: { unique: input.for.tunnel.into.cluster } }, context) ??
    BadRequestError.throw('cluster not found for tunnel hash', { input });

  if (!cluster.host?.writer || !cluster.port)
    BadRequestError.throw('cluster missing host or port', { input, cluster });

  // compute deterministic hash
  return crypto
    .createHash('sha256')
    .update(`${bastion.id}:${cluster.host.writer}:${cluster.port}:${input.for.tunnel.from.port}`)
    .digest('hex')
    .slice(0, 16);
};


why not just compute the cache based on `serialize(input.for.tunnel)` ?



===

# nitpick.3

lets be consistent in name convention

fileExists => isFilePresent


===

# blocker.4


const DEFAULT_TUNNELS_DIR = path.join(os.homedir(), '.declastruct', 'tunnels');


default tunnels dir should oly bneed to be specified in the getContext procedure

it should set the default if wansn't provided by user

and the context interface itself should always have it declared

=>

limit the spread of default casting as far upfront as possible => decrease codepaths


===

# nitpick.5

return new DeclaredAwsVpcTunnel({ ...input, status: 'CLOSED' }) as HasMetadata<DeclaredAwsVpcTunnel>;

====

# blocker.6

we can elminate more if/elses and make this more of a simple narrative

instead of

```ts

      // check if our tunnel process is alive
      if (!isProcessAlive({ pid })) {
        // process dead but pidfile exists; cleanup and respawn
        await fs.rm(pidPath, { force: true });
        await fs.rm(metaPath, { force: true });
        // fall through to spawn new tunnel
      } else {
        // process alive; check if healthy
        const healthy = await isTunnelHealthy({ port: input.from.port });
        if (healthy) {
          return new DeclaredAwsVpcTunnel({ ...input, status: 'OPEN', pid }) as HasMetadata<DeclaredAwsVpcTunnel>;
        }

        // tunnel process alive but not healthy; kill and respawn
        process.kill(pid, 'SIGTERM');
        await fs.rm(pidPath, { force: true });
        await fs.rm(metaPath, { force: true });
        // fall through to spawn new tunnel
      }
```

use

```ts
      // check if our tunnel process is alive
      if (isProcessAlive({ pid }) && await isTunnelHealthy({ port: input.from.port }))
        return new DeclaredAwsVpcTunnel({ ...input, status: 'OPEN', pid }) as HasMetadata<DeclaredAwsVpcTunnel>;

      // otherwise, tunnel is either dead or unhealthy; cleanup, then fallthrough to respawn
      process.kill(pid, 'SIGTERM');
      await fs.rm(pidPath, { force: true });
      await fs.rm(metaPath, { force: true });
```


# blocker.7

persist both the pid and metadata in one file

no use tohave two saeparate files
just make it one json


----

# blocker.8

getVpcTunnel should not need to as DeclaredAwsVpcTunnel

getTunnelHash({ for: { tunnel: input as DeclaredAwsVpcTunnel } }


it's input should be


export const getVpcTunnel = asProcedure(
  async (
    input: { by: { unique: RefByUnique<typeof DeclaredAwsVpcTunnel>}}


which is exactly assignable to the input of getTunnelHash
